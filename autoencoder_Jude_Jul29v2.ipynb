{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83df4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd33dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/judepereira/Downloads/ieee-fraud-detection/train_transaction.csv\")\n",
    "\n",
    "# derive “day” from TransactionDT, then drop the raw column\n",
    "df[\"day\"] = (df[\"TransactionDT\"] // (3600 * 24)).astype(int)\n",
    "df.drop(\"TransactionDT\", axis=1, inplace=True)\n",
    "\n",
    "# drop TransactionID, as it is not useful for modeling\n",
    "df.drop(\"TransactionID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b02aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a435cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81da5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute missing % for all columns\n",
    "nulls = df.isna().mean() * 100\n",
    "\n",
    "# find columns with more than 80% missing values\n",
    "cols_80 = nulls[nulls >= 80].index.tolist()\n",
    "\n",
    "# and drop them!\n",
    "df.drop(columns=cols_80, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b01e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# numeric imputation (median) – exclude the target “isFraud”\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols.remove(\"isFraud\")\n",
    "\n",
    "# among num_cols, find columns with nans that need to be imputed\n",
    "nan_cols = [c for c in num_cols if df[c].isna().any()]\n",
    "\n",
    "# exclude the categorical columns card2, card3, card5, addr1, addr2\n",
    "cat_cols = [\"card2\", \"card3\", \"card5\", \"addr1\", \"addr2\"]\n",
    "nan_cols = [c for c in nan_cols if c not in cat_cols]\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "df[nan_cols] = imputer.fit_transform(df[nan_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26124b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for remaining categoricals, one‐hot encode small‐cardinaliy ones else drop them\n",
    "cat_cols_rem = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# include the cat_cols that were excluded earlier\n",
    "cat_cols_rem.extend(cat_cols)\n",
    "\n",
    "# e.g. “ProductCD”, “MISSING” placeholders, etc.\n",
    "for c in cat_cols_rem:\n",
    "    n_uniq = df[c].nunique()\n",
    "    if n_uniq <= 10:\n",
    "        dummies = pd.get_dummies(df[c], prefix=c, drop_first=True)\n",
    "        df = pd.concat([df.drop(c, axis=1), dummies], axis=1)\n",
    "    else:\n",
    "        df.drop(columns=c, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c7d3f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>dist1</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>...</th>\n",
       "      <th>M1_T</th>\n",
       "      <th>M2_T</th>\n",
       "      <th>M3_T</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "      <th>M5_T</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>M7_T</th>\n",
       "      <th>M8_T</th>\n",
       "      <th>M9_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionAmt  card1  dist1   C1   C2   C3   C4   C5   C6  ...  \\\n",
       "0        0            68.5  13926   19.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "1        0            29.0   2755    8.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "2        0            59.0   4663  287.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "3        0            50.0  18132    8.0  2.0  5.0  0.0  0.0  0.0  4.0  ...   \n",
       "4        0            50.0   4497    8.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "\n",
       "    M1_T   M2_T   M3_T  M4_M1  M4_M2   M5_T   M6_T   M7_T   M8_T   M9_T  \n",
       "0   True   True   True  False   True  False   True  False  False  False  \n",
       "1  False  False  False  False  False   True   True  False  False  False  \n",
       "2   True   True   True  False  False  False  False  False  False  False  \n",
       "3  False  False  False  False  False   True  False  False  False  False  \n",
       "4  False  False  False  False  False  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bb5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all bool columns in df\n",
    "bool_cols = df.select_dtypes(include=\"bool\").columns\n",
    "\n",
    "# cast them to int (True→1, False→0)\n",
    "df[bool_cols] = df[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38d6a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>dist1</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>...</th>\n",
       "      <th>M1_T</th>\n",
       "      <th>M2_T</th>\n",
       "      <th>M3_T</th>\n",
       "      <th>M4_M1</th>\n",
       "      <th>M4_M2</th>\n",
       "      <th>M5_T</th>\n",
       "      <th>M6_T</th>\n",
       "      <th>M7_T</th>\n",
       "      <th>M8_T</th>\n",
       "      <th>M9_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud  TransactionAmt  card1  dist1   C1   C2   C3   C4   C5   C6  ...  \\\n",
       "0        0            68.5  13926   19.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "1        0            29.0   2755    8.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "2        0            59.0   4663  287.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "3        0            50.0  18132    8.0  2.0  5.0  0.0  0.0  0.0  4.0  ...   \n",
       "4        0            50.0   4497    8.0  1.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "\n",
       "   M1_T  M2_T  M3_T  M4_M1  M4_M2  M5_T  M6_T  M7_T  M8_T  M9_T  \n",
       "0     1     1     1      0      1     0     1     0     0     0  \n",
       "1     0     0     0      0      0     1     1     0     0     0  \n",
       "2     1     1     1      0      0     0     0     0     0     0  \n",
       "3     0     0     0      0      0     1     0     0     0     0  \n",
       "4     0     0     0      0      0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d4311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Training on normals only: (455901, 338)\n",
      "→ CV set (normals+fraud): (134639, 338)\n"
     ]
    }
   ],
   "source": [
    "# Create training and CV sets\n",
    "# all non‐fraud examples\n",
    "df_norm = df[df.isFraud == 0].copy()\n",
    "# all fraud examples\n",
    "df_fraud = df[df.isFraud == 1].copy()\n",
    "\n",
    "# hold out 20% of normals for CV\n",
    "norm_train, norm_cv = train_test_split(\n",
    "    df_norm, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# CV set = held‐out normals + all frauds\n",
    "df_cv = pd.concat([norm_cv, df_fraud], axis=0)\n",
    "y_cv  = df_cv[\"isFraud\"].values\n",
    "\n",
    "# drop labels for modeling\n",
    "X_train = norm_train.drop(\"isFraud\", axis=1)\n",
    "X_cv    = df_cv.drop(\"isFraud\", axis=1)\n",
    "\n",
    "print(\"→ Training on normals only:\", X_train.shape)\n",
    "print(\"→ CV set (normals+fraud):\", X_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify one-hot columns (all values are 0 or 1)\n",
    "one_hot_cols = [col for col in X_train.columns if set(X_train[col].unique()) <= {0, 1}]\n",
    "non_one_hot_cols = [col for col in X_train.columns if col not in one_hot_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a6cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_cv_scaled    = X_cv.copy()\n",
    "\n",
    "X_train_scaled[non_one_hot_cols] = scaler.fit_transform(X_train[non_one_hot_cols])\n",
    "X_cv_scaled[non_one_hot_cols]    = scaler.transform(X_cv[non_one_hot_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f9baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_scaled.values\n",
    "X_cv_final    = X_cv_scaled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6321be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "x_train = torch.FloatTensor(X_train_final)\n",
    "x_valid = torch.FloatTensor(X_cv_final)\n",
    "y_valid = torch.FloatTensor(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9baaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output must match the input for autoencoders\n",
    "\n",
    "class FraudDatasetUnsupervised(Dataset):\n",
    "    \n",
    "    def __init__(self, x,output=True):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.output = output\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample index\n",
    "        item = self.x[index]\n",
    "        if self.output:\n",
    "            return item, item\n",
    "        else:\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b3d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FraudDatasetUnsupervised(x_train)\n",
    "valid_set = FraudDatasetUnsupervised(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Pytorch loaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(valid_set,   batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DropAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, intermediate_size_1, intermediate_size_2, code_size, dropout_rate=0.2):\n",
    "        super(DropAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_size, intermediate_size_1)\n",
    "        self.fc2 = nn.Linear(intermediate_size_1, intermediate_size_2)\n",
    "        self.fc3 = nn.Linear(intermediate_size_2, code_size)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc4 = nn.Linear(code_size, intermediate_size_2)\n",
    "        self.fc5 = nn.Linear(intermediate_size_2, intermediate_size_1)\n",
    "        self.fc6 = nn.Linear(intermediate_size_1, input_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder with dropout noise\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        code = F.relu(self.fc3(x))\n",
    "        \n",
    "        # Decoder\n",
    "        x = F.relu(self.fc4(code))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        output = self.fc6(x)  # Linear activation\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a15fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9665bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_sample_mse(model, generator):\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "    batch_losses = []\n",
    "    \n",
    "    for x_batch, y_batch in generator:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())\n",
    "        batch_losses.extend(loss_app)\n",
    "    \n",
    "    return batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e91dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "model = DropoutAutoencoder(x_train.shape[1], 128, 64, 16, dropout_rate=0.2)\n",
    "losses = per_sample_mse(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "721b65cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float32(0.10466372), np.float32(3.11748), np.float32(0.12473496), np.float32(0.24563716), np.float32(0.9639551)]\n",
      "2.0011084\n"
     ]
    }
   ],
   "source": [
    "print(losses[0:5])\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66da7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,generator,criterion):\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in generator:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        batch_losses.append(loss.item())\n",
    "    mean_loss = np.mean(batch_losses)    \n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04b30bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \n",
    "    def __init__(self, patience=3, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = np.inf\n",
    "    \n",
    "    def continue_training(self,current_score):\n",
    "        if self.best_score > current_score:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(\"New best score:\", current_score)\n",
    "        else:\n",
    "            self.counter+=1\n",
    "            if self.verbose:\n",
    "                print(self.counter, \" iterations since best score.\")\n",
    "                \n",
    "        return self.counter <= self.patience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4465904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=3,verbose=False):\n",
    "    #Setting the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    if apply_early_stopping:\n",
    "        early_stopping = EarlyStopping(verbose=verbose,patience=patience)\n",
    "    \n",
    "    all_train_losses = []\n",
    "    all_valid_losses = []\n",
    "    \n",
    "    #Training loop\n",
    "    start_time=time.time()\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_loss=[]\n",
    "        for x_batch, y_batch in training_generator:\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(x_batch)\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), y_batch)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        #showing last training loss after each epoch\n",
    "        all_train_losses.append(np.mean(train_loss))\n",
    "        if verbose:\n",
    "            print('')\n",
    "            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
    "        #evaluating the model on the test set after each epoch    \n",
    "        valid_loss = evaluate_model(model,valid_generator,criterion)\n",
    "        all_valid_losses.append(valid_loss)\n",
    "        if verbose:\n",
    "            print('valid loss: {}'.format(valid_loss))\n",
    "        if apply_early_stopping:\n",
    "            if not early_stopping.continue_training(valid_loss):\n",
    "                if verbose:\n",
    "                    print(\"Early stopping\")\n",
    "                break\n",
    "        \n",
    "    training_execution_time=time.time()-start_time\n",
    "    return model,training_execution_time,all_train_losses,all_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d616349",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef8007f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.6331581974392657\n",
      "valid loss: 1.2728861896923174\n",
      "New best score: 1.2728861896923174\n",
      "\n",
      "Epoch 1: train loss: 0.4862475634815568\n",
      "valid loss: 1.1259676744743559\n",
      "New best score: 1.1259676744743559\n",
      "\n",
      "Epoch 2: train loss: 0.43702311404593236\n",
      "valid loss: 1.0216602943448116\n",
      "New best score: 1.0216602943448116\n",
      "\n",
      "Epoch 3: train loss: 0.41130547048518795\n",
      "valid loss: 0.9358362278798347\n",
      "New best score: 0.9358362278798347\n",
      "\n",
      "Epoch 4: train loss: 0.39362815840421833\n",
      "valid loss: 0.8720011000163825\n",
      "New best score: 0.8720011000163825\n",
      "\n",
      "Epoch 5: train loss: 0.37965981093230605\n",
      "valid loss: 0.8317107914950514\n",
      "New best score: 0.8317107914950514\n",
      "\n",
      "Epoch 6: train loss: 0.3662534802001658\n",
      "valid loss: 0.8018558256172296\n",
      "New best score: 0.8018558256172296\n",
      "\n",
      "Epoch 7: train loss: 0.3542225208731681\n",
      "valid loss: 0.7583249913202775\n",
      "New best score: 0.7583249913202775\n",
      "\n",
      "Epoch 8: train loss: 0.3467012395060494\n",
      "valid loss: 0.746712317991251\n",
      "New best score: 0.746712317991251\n",
      "\n",
      "Epoch 9: train loss: 0.34104405609385674\n",
      "valid loss: 0.7334111419899438\n",
      "New best score: 0.7334111419899438\n",
      "\n",
      "Epoch 10: train loss: 0.33168614791588025\n",
      "valid loss: 0.7151904239074925\n",
      "New best score: 0.7151904239074925\n",
      "\n",
      "Epoch 11: train loss: 0.32815976021105425\n",
      "valid loss: 0.7005825737958682\n",
      "New best score: 0.7005825737958682\n",
      "\n",
      "Epoch 12: train loss: 0.32306270081505956\n",
      "valid loss: 0.6931166602511086\n",
      "New best score: 0.6931166602511086\n",
      "\n",
      "Epoch 13: train loss: 0.3182048078611752\n",
      "valid loss: 0.6880943557112956\n",
      "New best score: 0.6880943557112956\n",
      "\n",
      "Epoch 14: train loss: 0.31635149348169517\n",
      "valid loss: 0.6717459828143111\n",
      "New best score: 0.6717459828143111\n",
      "\n",
      "Epoch 15: train loss: 0.3139295270765835\n",
      "valid loss: 0.6747229291593564\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 16: train loss: 0.3103873496001889\n",
      "valid loss: 0.6581955127729663\n",
      "New best score: 0.6581955127729663\n",
      "\n",
      "Epoch 17: train loss: 0.30970425177145916\n",
      "valid loss: 0.6702266102656722\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 18: train loss: 0.31254761332854136\n",
      "valid loss: 0.6571289487714267\n",
      "New best score: 0.6571289487714267\n",
      "\n",
      "Epoch 19: train loss: 0.3077968481106078\n",
      "valid loss: 0.6374256500492701\n",
      "New best score: 0.6374256500492701\n",
      "\n",
      "Epoch 20: train loss: 0.3026482237326185\n",
      "valid loss: 0.651146734090869\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 21: train loss: 0.3043563267104181\n",
      "valid loss: 0.6517309066007346\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 22: train loss: 0.3034704132470972\n",
      "valid loss: 0.6454728728110686\n",
      "3  iterations since best score.\n",
      "\n",
      "Epoch 23: train loss: 0.29807413785871595\n",
      "valid loss: 0.6472519792000208\n",
      "4  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model,training_execution_time,train_losses,valid_losses = training_loop(model,train_loader,val_loader,optimizer,criterion,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4baa1f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float32(0.0058943215), np.float32(0.9047979), np.float32(0.01538955), np.float32(0.035126124), np.float32(0.35696024)]\n",
      "0.647031\n"
     ]
    }
   ],
   "source": [
    "losses = per_sample_mse(model, val_loader)\n",
    "print(losses[0:5])\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9855e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fraud reconstruction error: 2.977164\n",
      "Average genuine reconstruction error: 0.22459523\n"
     ]
    }
   ],
   "source": [
    "genuine_losses = np.array(losses)[y_valid.numpy() == 0]\n",
    "fraud_losses = np.array(losses)[y_valid.numpy() == 1]\n",
    "print(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\n",
    "print(\"Average genuine reconstruction error:\", np.mean(genuine_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f88db505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics import (average_precision_score, roc_auc_score)\n",
    "\n",
    "# compute AUC-ROC and Average Precision on the validation set by considering the reconstruction errors as predicted fraud scores\n",
    "\n",
    "AUC_ROC = roc_auc_score(y_cv, losses)\n",
    "AP = average_precision_score(y_cv, losses)\n",
    "    \n",
    "performances = pd.DataFrame([[AUC_ROC, AP]], columns=['AUC ROC','Average precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd5bf37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743221</td>\n",
       "      <td>0.477684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AUC ROC  Average precision\n",
       "0  0.743221           0.477684"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3ccea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at threshold 0.1756 = 0.6274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "thr      = np.percentile(losses, 70)      # e.g. top 30% as “fraud”\n",
    "y_pred   = (losses >= thr).astype(int)\n",
    "recall   = recall_score(y_cv, y_pred)    # binary‐class recall\n",
    "print(f\"Recall at threshold {thr:.4f} = {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
